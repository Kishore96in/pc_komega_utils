"""
Replace power*_xy.dat with HDF5 files containing the same information
"""

import h5py
import pathlib
import numpy as np
import pencil as pc
import warnings

def powerxy_to_hdf5(
	power_name,
	file_name,
	datadir,
	out_file = None,
	compression = None,
	):
	"""
	Convert power*_xy.dat to a HDF5 file containing the same information
	
	Logic is copied from pc.read.powers.Power._read_power2d
	
	Arguments:
		power_name: str. Key to use for the spectrum in the resulting HDF5 file (e.g. "uz_xy").
		file_name: str. Name of the .dat file (e.g. "poweruz_xy.dat").
		datadir: str or pathlib.Path (e.g. "./data").
	
	Optional arguments:
		outfile: str or pathlib.Path. The path at which the HDF5 file should be created (e.g. "./data/poweruz_xy.h5").
		compression: str. Controls compression of the HDF5 dataset. Legal values are 'gzip', 'szip', 'lzf'.  If an integer in range(10), this indicates gzip compression level.
	"""
	
	datadir = pathlib.Path(datadir)
	
	basename = file_name.removesuffix(".dat")
	
	if out_file is None:
		out_file = datadir/f"{basename}.h5"
	
	dtype_f = np.single
	dtype_c = np.csingle
	dtype_i = np.int64
	
	dim = pc.read.dim(datadir=datadir)
	param = pc.read.param(datadir=datadir)
	
	with (
		h5py.File(out_file, mode='x') as f_out,
		open(datadir/file_name, mode='r') as f,
		):
		_ = f.readline()  # ignore first line
		header = f.readline()
		
		# Get k vectors:
		if param.lintegrate_shell:
			nk = int(
				header
				.split()[header.split().index("k") + 1]
				.split(")")[0][1:]
				)
			k = []
			for _ in range(int(np.ceil(nk / 8))):
				line = f.readline()
				k.extend([float(j) for j in line.split()])
			k = np.array(k, dtype=dtype_f)
			f_out.create_dataset("k", data=k)
		else:
			nkx = int(
				header
				.split()[header.split().index("k_x") + 1]
				.split(")")[0][1:]
				)
			kx = []
			for _ in range(int(np.ceil(nkx / 8))):
				line = f.readline()
				kx.extend([float(j) for j in line.split()])
			kx = np.array(kx, dtype=dtype_f)
			f_out.create_dataset("kx", data=kx)

			nky = int(
				header
				.split()[header.split().index("k_y") + 1]
				.split(")")[0][1:]
				)
			ky = []
			for _ in range(int(np.ceil(nky / 8))):
				line = f.readline()
				ky.extend([float(j) for j in line.split()])
			ky = np.array(ky, dtype=dtype_f)
			f_out.create_dataset("ky", data=ky)

			nk = nkx * nky

		# Now read z-positions, if any
		if param.lintegrate_z:
			nzpos = 1
		else:
			ini = f.tell()
			line = f.readline()
			if "z-pos" in line:
				nzpos = int(re.search(r"\((\d+)\)", line)[1])
				block_size = int(np.ceil(nzpos / 8))
				zpos = []
				for _ in range(block_size):
					line = f.readline()
					zpos.extend([float(j) for j in line.split()])
				f_out.create_dataset("zpos", data=np.array(zpos, dtype=dtype_f))
			else:
				# there was no list of z-positions, so reset the position of the reader.
				f.seek(ini)

				nzpos = dim.nzgrid
				grid = pc.read.grid(datadir=datadir, trim=True, quiet=True)
				f_out.create_dataset("zpos", data=grid.z, dtype=dtype_f)

		# Now read the rest of the file
		time = []
		its = []

		if param.lintegrate_shell:
			block_size = np.ceil(nk / 8) * nzpos + 1
		else:
			block_size = np.ceil(int(nk * nzpos) / 8) + 1
		
		f_out.create_group(power_name)
		f_out.create_dataset("version", data=np.array([1,0,0], dtype=dtype_i))
		
		
		def _write_power_array(power_array, it):
			if param.lintegrate_shell or (dim.nxgrid == 1 or dim.nygrid == 1):
				power_array = power_array.reshape([nzpos, nk])
			else:
				power_array = power_array.reshape([nzpos, nky, nkx])
			
			f_out[power_name].create_dataset(
				str(it),
				data=power_array,
				compression=compression,
				)
		
		first = True
		it = 0
		for line_idx, line in enumerate(f):
			if line_idx % block_size == 0:
				if not first:
					_write_power_array(power_array, it)
				
				first = False
				
				t = float(line.strip())
				it += 1
				time.append(t)
				its.append(it)
				
				if param.lcomplex:
					power_array = np.zeros(nzpos*nk, dtype=dtype_c)
				else:
					power_array = np.zeros(nzpos*nk, dtype=dtype_f)
				
				ik = 0
			else:
				lsp = line.strip().split()

				if param.lcomplex:
					# complex power spectrum
					real = lsp[0::2]
					imag = lsp[1::2]
					for a, b in zip(real, imag):
						power_array[ik] = float(a) + 1j * float(b)
						ik += 1
				else:
					for value_string in lsp:
						power_array[ik] = float(value_string)
						ik += 1
		
		#Last one has still not been written
		_write_power_array(power_array, it)
		
		f_out.create_group("times")
		f_out['times'].create_dataset("it", data=np.array(its, dtype=dtype_i))
		f_out['times'].create_dataset("t", data=np.array(time, dtype=dtype_f))
		
		f_out.create_dataset("nzpos", data=nzpos, dtype=dtype_i)

class read_power():
	"""
	Replacement for pc.read.powers.Power that uses the HDF5 file(s) generated by powerxy_to_hdf5.
	
	Optional arguments:
		datadir: str or pathlib.Path (default: "./data")
		z: list. Read only spectra at these z values. By default, all z values are read.
	"""
	
	def __init__(self, datadir="./data", z=None):
		datadir = pathlib.Path(datadir)
		files = datadir.glob("power*_xy.h5")
		
		for file_name in files:
			with h5py.File(file_name) as f:
				for k in ["nzpos", "kx", "ky", "k"]:
					if k in f.keys():
						self.safe_setattr(k, f[k][()])
				
				self.safe_setattr("t", f['times/t'][()])
				
				z_full = f['zpos'][()]
				if z is None:
					self.safe_setattr("z", z_full)
					izs = range(len(z_full))
				else:
					izs = []
					for i, z_val in enumerate(z):
						izs.append(np.argmin(np.abs(z_full - z_val)))
					
					izs = np.unique(izs)
					
					if len(izs) < len(z):
						warnings.warn("Spacing between the specified z values is less than the grid spacing; dropping duplicates.")
					
					self.safe_setattr("z", z_full[izs])
				
				[power_name] = [name for name in f.keys() if name[-3:] == "_xy"]
				its = f['times/it'][()]
				
				power_array = []
				
				for it in its:
					power = f[power_name][str(it)]
					power_array.append(power[izs])
					dtype = power.dtype
				
				self.safe_setattr(power_name, np.array(power_array, dtype=dtype))
	
	def safe_setattr(self, attr, value):
		if hasattr(self, attr):
			if not np.all(getattr(self, attr) == value):
				raise RuntimeError(f"Mismatch in values of key {attr}")
		else:
			setattr(self, attr, value)

class m_pxy_h5():
	"""
	Mixin to be used with dr_pxy_base.
	
	This uses read_power.
	
	"""
	def __init__(self, *args, **kwargs):
		self._z_to_keep = kwargs.pop('z', None)
		
		super().__init__(*args, **kwargs)
	
	def read_power(self):
		return read_power(
			datadir = self.datadir,
			z = self._z_to_keep,
			)
